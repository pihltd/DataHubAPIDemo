{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "796de190-d963-41ec-8378-a9b6cec3b4b1",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook walks through the basics of using the Data Hub API to work on, validate, and submit your data.  These APIs are designed to allow users to perform all the actions that can be done via the [Data Submission Portal](https://hub.datacommons.cancer.gov/) from a notebook or script.  The intent is to allow submitters to operate directly from their own environments if they so choose rathar than work through the graphical submission interface.\n",
    "\n",
    "There are a few prerequists that you have to meet before you can use this API:\n",
    "\n",
    "# Prerequisites\n",
    "\n",
    "## GraphQL\n",
    "The Data Hub API uses [GraphQL](https://graphql.org/) and a good understanding of how to use GraphQL is required.  Since GraphQL can be complex, a tutorial is beyond the scope of this document, however the [GraphQL Documentation](https://graphql.org/learn/) can be very useful.\n",
    "\n",
    "## Login.gov account\n",
    "Use of Data Hub in general requires that a user have an account registered with [Login.gov](https://www.login.gov/) (NIH users can use their NIH account and PIV card).  Note that a Login.gov account is distinct from an eRA Commons identity that is frequently used at NIH.  They are not the same thing.\n",
    "\n",
    "## Approved Submission\n",
    "You must recieve approval to submit data to CRDC prior to using the Data Hub APIs.  If you need approval, please read and follow the [Submissions Request Instructions](https://datacommons.cancer.gov/submit).  Instructions for using the graphical data submission process are on the same page.\n",
    "\n",
    "## An API Token\n",
    "If you are an approved submitter with a Login.gov or NIH account, you can generate an API token from the graphical interface.  Log into the system, then click on your user name and select the **API Token** menu option.  This will bring up a dialog box that allows you to create an API token and copy it to your clipboard.  There are two things to note about API tokens\n",
    "- The token is tied to your user identity and can be used on any submission that you're approved to work on.\n",
    "- You can have only one token at a time.  Generating a new token will revoke the previous token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43cfe135-2892-4989-a90b-3560512ccebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1454ae-b351-44ac-82c0-de89600e4094",
   "metadata": {},
   "source": [
    "The imports below are just used for display purposes in this notebook, they're not required to interact with the Data Hub API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39da5f4-1a17-4ee8-bf6b-1925631ef734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, Markdown, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55273b38-3bf5-4e05-b23b-39045ef76dd2",
   "metadata": {},
   "source": [
    "API Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10985da9-52b1-4baf-ad46-a939aaadb38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = 'https://hub.datacommons.cancer.gov/api/graphql'\n",
    "#Note that use of Dev2 requires a VPN connection through the NIH firewall\n",
    "dev2 = 'https://hub-dev2.datacommons.cancer.gov/api/graphql'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e1712-b36a-445f-9822-3946d9e5626f",
   "metadata": {},
   "source": [
    "# Security Note\n",
    "It is ***highly*** recommended that you keep your API token secure and not include it in any code.  While there are many ways to do this, for the purposes of this notebook it's been set in an environment variable names \"DEV2API\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e17c3d7d-24a3-403d-874b-8bfaea3f2387",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev2APIKey = os.environ['DEV2API']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01bdddfe-4b2f-4bb8-8762-2bc9411054fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apiQuery(url, query, variables,headers):\n",
    "    token = os.environ['DEV2API']\n",
    "    if headers is None:\n",
    "        headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    else:\n",
    "        headers[\"Authorization\"] = f\"Bearer {token}\"\n",
    "    try:\n",
    "        if variables is None:\n",
    "            result = requests.post(url = url, headers = headers, json={\"query\": query})\n",
    "        else:\n",
    "            result = requests.post(url = url, headers = headers, json = {\"query\":query, \"variables\":variables})\n",
    "        if result.status_code == 200:\n",
    "            return result.json()\n",
    "        else:\n",
    "            print(f\"Error: {result.status_code}\")\n",
    "            return result.content\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        return(f\"HTTP Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e929828f-fef2-4fb7-8ffd-6e3ec7d73d2b",
   "metadata": {},
   "source": [
    "# Step 1: Understanding the landscape\n",
    "\n",
    "Let's assume that this is our first submission using the API, so what we need to do is list the studies that my orgnaization is approved for so I can submit to the correct study. That's done with the *listApprovedStudiesOfMyOrganization* query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6802fa1-7b99-4ce3-a867-b0ad6b83b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_query = \"\"\"\n",
    "{\n",
    "  listApprovedStudiesOfMyOrganization{\n",
    "    originalOrg\n",
    "    dbGaPID\n",
    "    studyAbbreviation\n",
    "    studyName\n",
    "    _id\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d8036d-5474-4bbb-b2fc-1d4f91c63fad",
   "metadata": {},
   "source": [
    "Note that the actual results returned by this query will vary for each organization.  These are examples only and shouldn't be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "122289b5-c6c0-4a34-b865-a1fc82f57595",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_res = apiQuery(dev2, org_query,None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a11ef7-bd6d-4375-8188-ba5f75a37c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|    | originalOrg                                    | dbGaPID   | studyAbbreviation   | studyName                                                                                       | _id                                  |\n",
       "|---:|:-----------------------------------------------|:----------|:--------------------|:------------------------------------------------------------------------------------------------|:-------------------------------------|\n",
       "|  0 | Purdue Center for Cancer Research              |           | UBC01               | Antitumor Activity and Molecular Effects of Vemurafenib in Dogs with BRAF-mutant Bladder Cancer | b9e9ab79-d90b-4ec1-83b7-f83a5a75f5b5 |\n",
       "|  1 | Comparative Molecular Characterization Program |           | OSA01               | A Multi-Platform Sequencing Analysis of Canine Appendicular Osteosarcoma                        | e3feefe9-cc70-4ae0-be06-9df7f29d84e8 |\n",
       "|  2 | Comparative Molecular Characterization Program |           | TCL01               | Whole exome sequencing analysis of canine cancer cell lines                                     | 6c7fa436-efa3-42c6-af4c-7f5b70a1d35d |\n",
       "|  3 | NCI BBRB                                       |           | CMB                 | Cancer Moonshot Biobank                                                                         | 4c2b6522-20b8-4841-8c7a-318b325c99b4 |\n",
       "|  4 | CCDI                                           | phs003432 | TALLsc              | T-cell Acute Lymphoblastic Leukemia Single Cell RNA Sequencing and ATAC Sequencing              | 49a69fef-71f8-44e6-ad3b-f7a62d91e348 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "org_df = pd.DataFrame(org_res['data']['listApprovedStudiesOfMyOrganization'])\n",
    "display(Markdown(org_df.to_markdown()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08abf99-9543-46ad-abfa-1cca90c88a1b",
   "metadata": {},
   "source": [
    "# Step 2:  Creating a new submission or using an existing submission\n",
    "\n",
    "The next step in the process is to either create a new submission or to use one of your existing submissions.  It is not necessary to create a new submission every time, if you have an existing submission that you need to continue working on, simply start using that submission. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397c83f4-c77f-4951-833d-4053a422d08b",
   "metadata": {},
   "source": [
    "## Step 2, Alternate 1: Creating a new submission\n",
    "\n",
    "For the purposes of this demonstration, we'll use the CCDI TALLsc study as the example.  In order to submit data you first step create a new submission within the study.  **Do not do this if you're continuing with an exsiting study**.\n",
    "\n",
    "From the data we obtained in the first query, we'll have to parse out the infrmiaton that's relevant to the CCDI TALLsc study.  We'll need these to construct the query that creates the new submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c140b0b8-598a-4a00-999f-0750f52a9384",
   "metadata": {},
   "outputs": [],
   "source": [
    "for study in org_res['data']['listApprovedStudiesOfMyOrganization']:\n",
    "    if study['originalOrg'] == 'CCDI':\n",
    "        org = study['originalOrg']\n",
    "        dbgap = study['dbGaPID']\n",
    "        abbrev = study['studyAbbreviation']\n",
    "        name = study['studyName']\n",
    "        studyid = study['_id']\n",
    "\n",
    "dc = \"CDS\"\n",
    "name = \"Jupyter Demo 3\"\n",
    "intention = \"New/Update\"\n",
    "datatype = \"Metadata and Data Files\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fbfeb7-5de1-45ab-a692-5e44f83f5719",
   "metadata": {},
   "source": [
    "### createSubmissions mutation\n",
    "\n",
    "Creating submissions requires the use of a mutation that calls createSubmissions.  There are multiple required variables that have to be provided in a GraphQL compatible way:\n",
    "- studyID:  This is the Study ID that can be obtained from the graphical interface\n",
    "- dbGaPID: Obtained when registering the study at dbGaP.  This is required for all controlled access studies\n",
    "- dataCommons: This is the CRDC Data Commons the submissions will be deposited in\n",
    "- name: This can be anything that allows you to identify this specific submission\n",
    "- intention: Can be “New/Update” if you are adding information to the submission or  “Delete” if you are removing information from the submission\n",
    "- dataType: Can be either \"Metadata and Data Files\" or “Metadata Only”.  Which one is selected depends on whether or not data files will be included in the submission\n",
    "\n",
    "  This query will return the _id field which will be the newly created submission ID. It will also return a number of other fields that can be checked to make sure the submission was created properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a68dec46-8ee1-4942-a7a3-8b3298acd530",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission_query = \"\"\"\n",
    "mutation CreateNewSubmission(\n",
    "  $studyID: String!,\n",
    "  $dbGaPID: String!,\n",
    "  $dataCommons: String!,\n",
    "  $name: String!,\n",
    "  $intention:String!,\n",
    "  $dataType: String!,\n",
    "){\n",
    "  createSubmission(\n",
    "    studyID: $studyID,\n",
    "    dbGaPID: $dbGaPID,\n",
    "    dataCommons: $dataCommons,\n",
    "    name: $name,\n",
    "    intention: $intention,\n",
    "    dataType: $dataType\n",
    "  ){\n",
    "    _id\n",
    "    studyID\n",
    "    dbGaPID\n",
    "    dataCommons\n",
    "    name\n",
    "    intention\n",
    "    dataType\n",
    "    status\n",
    "  }\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "632a8907-6fa0-456d-878b-c01da43acd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = {\"studyID\":studyid, \"dbGaPID\":dbgap, \"dataCommons\":dc, \"name\":name, \"intention\":intention,\"dataType\":datatype}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5116aa6d-b0ca-43ef-bf1e-080cd35155f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_res = apiQuery(dev2,create_submission_query, variables, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "beda4077-fcaf-430c-af3a-730cb2ee9937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'createSubmission': {'_id': '162fb91f-75a8-4994-86e7-8df189ebc476', 'studyID': '49a69fef-71f8-44e6-ad3b-f7a62d91e348', 'dbGaPID': 'phs003432', 'dataCommons': 'CDS', 'name': 'Jupyter Demo 3', 'intention': 'New/Update', 'dataType': 'Metadata and Data Files', 'status': 'New'}}}\n"
     ]
    }
   ],
   "source": [
    "print(create_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4187daa2-dba6-4508-aee8-ae19ab831154",
   "metadata": {},
   "source": [
    "Parse out the submission ID since we'll need it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ecd2d52-cf09-4f92-9a6b-f128c5d58cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissionid = create_res['data']['createSubmission'][\"_id\"]\n",
    "subname = create_res['data']['createSubmission']['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261fc49a-6a3c-4f17-a7c3-78944ff3d79b",
   "metadata": {},
   "source": [
    "#### Side trip\n",
    "\n",
    "At this point if you go to the graphical interface you should see that a new submission has been created using the name provided in the query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320bc97-b1dd-4c20-8073-97f48a6c204c",
   "metadata": {},
   "source": [
    "### Step 2, Alternate 2: Working with existing submissions\n",
    "\n",
    "If you already have submissions in Data Hub that you've been working with, you can continue to work with them instead of creating a new submission.  To continue work on a submission, you will first have to identify the submissions using the *listSubmissions* query.\n",
    "\n",
    "The listSubmissions query requires that **status** be provided as a parameter.  The status can be one of:\n",
    "- \"All\"\n",
    "- \"New\"\n",
    "- \"In Progress\"\n",
    "- -\"Submitted\"\n",
    "- \"Released\"\n",
    "- \"Completed\"\n",
    "- \"Archived\"\n",
    "- \"Canceled\"\n",
    "- \"Rejected\"\n",
    "- \"Withdrawn\"-\n",
    "- \"Deleted\"\n",
    "\n",
    "This allows users to scan for submissions that are in a specific state, but for the purposes of the demonstration, we'll use \"All\" to bring back everything.  We'll also return some additional information about each submission so we can identify the ones we want to work with.\n",
    "\n",
    "For long lists, the *listSubmissions* query also allows the list to be sorted in ascending or descending order with the **sortDirection** field, and to request a sorting order by field with the **orderBy** field.  Additional fields for this query can be found in the documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98a8e86c-bceb-4d81-b8cb-46822a5c0673",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sub_query = \"\"\"\n",
    "    query ListSubmissions($status:String!){\n",
    "          listSubmissions(status: $status){\n",
    "            submissions{\n",
    "              _id\n",
    "              name\n",
    "              status\n",
    "              studyAbbreviation\n",
    "              studyID\n",
    "            }\n",
    "          }\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5287198-dd55-4c5a-8a64-85a1698f59ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "statusvariables = {\"status\":\"All\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e16543c9-4044-4855-813c-4c824a3c60a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sub_res = apiQuery(dev2, list_sub_query, statusvariables, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dee0bce-0a33-4443-af03-a2f0a7017554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|    | _id                                  | name                           | status      | studyAbbreviation   | studyID                              |\n",
       "|---:|:-------------------------------------|:-------------------------------|:------------|:--------------------|:-------------------------------------|\n",
       "|  0 | 162fb91f-75a8-4994-86e7-8df189ebc476 | Jupyter Demo 3                 | In Progress | TALLsc              | 49a69fef-71f8-44e6-ad3b-f7a62d91e348 |\n",
       "|  1 | f3eb4e0d-872c-4cbe-a758-0a2df9a1200d | Jupyter Demo 2                 | In Progress | TALLsc              | 49a69fef-71f8-44e6-ad3b-f7a62d91e348 |\n",
       "|  2 | 02862615-84b7-4815-becf-97a8593bf629 | Jupyter Demo 1                 | In Progress | TALLsc              | 49a69fef-71f8-44e6-ad3b-f7a62d91e348 |\n",
       "|  3 | eda77bf5-37cd-4f3b-822e-cbceb31fb05c | Demo create submission Jupyter | Canceled    | TALLsc              | 49a69fef-71f8-44e6-ad3b-f7a62d91e348 |\n",
       "|  4 | 04bd7dad-0859-49aa-8df1-5e6560e5482a | Demo create submission 1       | New         | TALLsc              | 49a69fef-71f8-44e6-ad3b-f7a62d91e348 |\n",
       "|  5 | d77df872-384f-493f-b18f-449ed6fa7fdb | Demo create submission Jupyter | In Progress | TALLsc              | 49a69fef-71f8-44e6-ad3b-f7a62d91e348 |\n",
       "|  6 | f41aea9c-bb76-4b48-8b53-27028317b434 | Demo create submission Jupyter | In Progress | TALLsc              | 49a69fef-71f8-44e6-ad3b-f7a62d91e348 |\n",
       "|  7 | 107ba083-f107-4a2f-a848-824bb8746a01 | Demo create submission 1       | New         | TALLsc              | 49a69fef-71f8-44e6-ad3b-f7a62d91e348 |\n",
       "|  8 | 181432cd-e915-46ff-b62e-1f167abb7e2f | API Demonstration              | New         | CMB                 | 4c2b6522-20b8-4841-8c7a-318b325c99b4 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submissions_df = pd.DataFrame(list_sub_res['data']['listSubmissions']['submissions'])\n",
    "display(Markdown(submissions_df.to_markdown()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43777d02-2c97-4622-9aa5-89403e2d3a83",
   "metadata": {},
   "source": [
    "Since we're working with the TALLsc study, we need to work on one of the submissions related to that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7dcfe5c-5a17-450b-9219-8bc28722ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for submission in list_sub_res['data']['listSubmissions']['submissions']:\n",
    "    if submission['name'] == 'Demo create submission Jupyter':\n",
    "        submissionid = submission['_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc62457-e4c8-4975-beef-1ff40e5d4b1b",
   "metadata": {},
   "source": [
    "# Step 3: Uploading Submission templates\n",
    "\n",
    "Once the study is created, the next step is to start uploading metadata submission templates.  There are two ways of accomplishing this upload:\n",
    "1) Using the Upload CLI Tool : This is generally the easiest method and can be used to upload both the metadata templates and the data files.  The use of the Uploader CLI Tool [is documented elsewhere](https://github.com/CBIIT/crdc-datahub-cli-uploader/tree/master)\n",
    "2) Using the API : If you wish to provide metadata only via a program, the API can be used as will be demonstrated in this notebook.\n",
    "\n",
    "**Note that while the API can be used to upload metadata, the actual data files MUST be uploaded with the Upload CLI Tool**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a2c287-4c8c-4b92-b173-26d908437777",
   "metadata": {},
   "source": [
    "## Collecting information about the metadata files to upload\n",
    "Let's set up the list of metadata files we want to upload.  This will be a list of **FileInput** objects.  A FileInput object consiste of a dictionary with *fileName* and *size* as the keys.\n",
    "\n",
    "- fileName: The full path file name.  Note that this will vary depending on the operating system being used.\n",
    "- size: The size of the file in bytes\n",
    "\n",
    "The last field required for the query is the *type* field is either \"metadata\" or \"data file\" and \"data file\" isn't allowed ouside of the Upload CLI Tool, we'll set it to \"metadata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f23cf46-d7a6-4951-bc1a-a3991f8ea10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f41aea9c-bb76-4b48-8b53-27028317b434\n"
     ]
    }
   ],
   "source": [
    "#metadatafiles = [{\"fileName\":\"/home/pihl/testdata/PDXNet_participant.tsv\", \"size\": 2106 }, {\"fileName\":\"/home/pihl/testdata/PDXNet_sample.tsv\", \"size\":12416}]\n",
    "#metadatafiles = [{\"fileName\":\"PDXNet_sample.tsv\", \"size\":12416}]\n",
    "metadatafiles = [{\"fileName\":\"PDXNet_participant.tsv\", \"size\": 2106 }, {\"fileName\":\"PDXNet_sample.tsv\", \"size\":12416},{\"fileName\":\"PDXNet_diagnosis.tsv\", \"size\":6439},{\"fileName\":\"PDXNet_file.tsv\", \"size\":76940},{\"fileName\":\"PDXNet_genomic_info.tsv\", \"size\":283886},{\"fileName\":\"PDXNet_image.tsv\", \"size\":3671},\n",
    "                      {\"fileName\":\"PDXNet_program.tsv\", \"size\":307},{\"fileName\":\"PDXNet_study.tsv\", \"size\":2171},{\"fileName\":\"PDXNet_treatment.tsv\", \"size\":112}]\n",
    "type = \"metadata\"\n",
    "uploadpath = \"/home/pihl/testdata/\"\n",
    "print(submissionid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1a4aef-cbd1-4613-9e78-1841188869bb",
   "metadata": {},
   "source": [
    "## The createBatch mutation\n",
    "Now that we've got credentials and the list of files, we create a \"batch\", which is the term for one or more files uploaded at the same time.  We do this by using the createBatch muations as shown below.  \n",
    "\n",
    "One of the critical pieces of information returned is the signed URL that is used to actually trasfer the files to Data Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50e5d7eb-87c2-4793-9700-f7782c277b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_batch_query = \"\"\"\n",
    "mutation CreateBatch(\n",
    "    $submissionID: ID!, \n",
    "    $type: String!, \n",
    "    $file: [FileInput]) {\n",
    "  createBatch(submissionID: $submissionID, type: $type, files: $file) {\n",
    "    _id\n",
    "    files {\n",
    "      fileName\n",
    "      signedURL\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d5977e3-b5a8-4d6f-bee7-a6d226a81f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_batch_variables = {\"submissionID\":submissionid, \"type\":type, \"file\":metadatafiles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83bb786e-cb8f-432c-9d45-594f52dceeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_batch_res = apiQuery(dev2, create_batch_query, create_batch_variables,None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27465b4-0281-499d-a473-2e9f3e6b4c39",
   "metadata": {},
   "source": [
    "The results from this mutation will have the signed URLs (again, for security reasons it's a good idea to not print them out).  We'll use these to upload the files.  Make sure that you're using the correct signed URL for each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cc4a8ac-4d6e-43ce-8b3c-7a26f054e1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e391e412-e4ad-4a91-ba5e-fc24cd106652\n"
     ]
    }
   ],
   "source": [
    "batchid = create_batch_res['data']['createBatch']['_id']\n",
    "print(batchid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f8061fb-bf78-46f7-a0c6-bb9ae57702cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def awsFileUpload(file, signedurl, size):\n",
    "#    #https://docs.aws.amazon.com/AmazonS3/latest/userguide/example_s3_Scenario_PresignedUrl_section.html\n",
    "#    #headers = {'Content-Type': 'text/tab-separated-values', 'Connection':'keep-alive', 'Accept':'*/*', 'Accept-Encoding':'gzip,deflate,br', 'Content-Length':str(size)}\n",
    "#    headers = {'Content-Type': 'text/tab-separated-values')}\n",
    "#    try:\n",
    "#        with open(file, 'rb') as f:\n",
    "#            filetext = f.read()\n",
    "#        res = requests.put(signedurl, data=filetext, headers=headers)\n",
    "#        if res.status_code == 200:\n",
    "#            return res\n",
    "#        else:\n",
    "#            print(f\"Error: {res.status_code}\")\n",
    "#            return res.content\n",
    "#    except requests.exceptions.HTTPError as e:\n",
    "#        return(f\"HTTP error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7725b40a-32fb-4d85-8902-fd2f7d7a9f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def awsFileUpload(file, signedurl, datadir):\n",
    "    #https://docs.aws.amazon.com/AmazonS3/latest/userguide/example_s3_Scenario_PresignedUrl_section.html\n",
    "    #headers = {'Content-Type': 'text/tab-separated-values', 'Connection':'keep-alive', 'Accept':'*/*', 'Accept-Encoding':'gzip,deflate,br', 'Content-Length':str(size)}\n",
    "    headers = {'Content-Type': 'text/tab-separated-values'}\n",
    "    try:\n",
    "        fullFileName = datadir+file\n",
    "        with open(fullFileName, 'rb') as f:\n",
    "            filetext = f.read()\n",
    "        res = requests.put(signedurl, data=filetext, headers=headers)\n",
    "        if res.status_code == 200:\n",
    "            return res\n",
    "        else:\n",
    "            print(f\"Error: {res.status_code}\")\n",
    "            return res.content\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        return(f\"HTTP error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6243889d-4a1a-49af-8efd-29bd482c267d",
   "metadata": {},
   "source": [
    "As each file is uploaded, an *UploadResult* object has to be constructed.  This will get used in the batch update step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d3d0193-ef9f-4722-9bb8-873a3febcea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_upload_result = []\n",
    "for entry in metadatafiles:\n",
    "    for metadatafile in create_batch_res['data']['createBatch']['files']:\n",
    "        if entry['fileName'] == metadatafile['fileName']:\n",
    "            metares = awsFileUpload(metadatafile['fileName'], metadatafile['signedURL'], uploadpath)\n",
    "            if metares.status_code == 200:\n",
    "                succeeded = True\n",
    "            else:\n",
    "                succeeded = False\n",
    "            file_upload_result.append({'fileName':entry['fileName'], 'succeeded': succeeded, 'errors':[], 'skipped':False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a860953a-2e91-4435-b593-fd90b50dc7bc",
   "metadata": {},
   "source": [
    "After files have been uploaded, the next step is to update the batch by calling the updateBatch mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ee67d21-c4d6-453e-be84-a84a37cdce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_batch_query = \"\"\"\n",
    "    mutation UpdateBatch(\n",
    "        $batchID: ID!\n",
    "        $files: [UploadResult]\n",
    "        ){\n",
    "        updateBatch(batchID:$batchID, files:$files){\n",
    "            _id\n",
    "            displayID\n",
    "        }\n",
    "        }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40c2ae66-3e04-4f88-a716-f1b7813d3637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'fileName': 'PDXNet_participant.tsv', 'succeeded': True, 'errors': [], 'skipped': False}, {'fileName': 'PDXNet_sample.tsv', 'succeeded': True, 'errors': [], 'skipped': False}, {'fileName': 'PDXNet_diagnosis.tsv', 'succeeded': True, 'errors': [], 'skipped': False}, {'fileName': 'PDXNet_file.tsv', 'succeeded': True, 'errors': [], 'skipped': False}, {'fileName': 'PDXNet_genomic_info.tsv', 'succeeded': True, 'errors': [], 'skipped': False}, {'fileName': 'PDXNet_image.tsv', 'succeeded': True, 'errors': [], 'skipped': False}, {'fileName': 'PDXNet_program.tsv', 'succeeded': True, 'errors': [], 'skipped': False}, {'fileName': 'PDXNet_study.tsv', 'succeeded': True, 'errors': [], 'skipped': False}, {'fileName': 'PDXNet_treatment.tsv', 'succeeded': True, 'errors': [], 'skipped': False}]\n"
     ]
    }
   ],
   "source": [
    "print(file_upload_result)\n",
    "#file_upload_result = [{\"fileName\":\"/home/pihl/testdata/PDXNet_participant.tsv\",\"succeeded\":True, \"errors\":[],\"skipped\":False},{\"fileName\":\"/home/pihl/testdata/PDXNet_sample.tsv\",\"succeeded\":True, \"errors\":[],\"skipped\":False}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d830262f-92c4-421b-b8c0-a99f800164fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_variables = {'batchID':batchid, 'files':file_upload_result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bebc154-061a-42aa-948e-11a4fc2b38e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e391e412-e4ad-4a91-ba5e-fc24cd106652\n",
      "{'data': {'updateBatch': {'_id': 'e391e412-e4ad-4a91-ba5e-fc24cd106652', 'displayID': 8}}}\n"
     ]
    }
   ],
   "source": [
    "update_res = apiQuery(dev2, update_batch_query, update_variables, None)\n",
    "print(batchid)\n",
    "print(update_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fcc0fe-3ae1-48dd-9849-75eb619d3441",
   "metadata": {},
   "source": [
    "#### Side Trip\n",
    "If you log into the Data Hub interface, at this point you should see the files that have been uploaded along with any errors that were detected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b8a2a1-b5e4-4f23-9fe1-0c4f72c420e8",
   "metadata": {},
   "source": [
    "### Checking the upload\n",
    "Before going any further, it's a good idea to make sure that the upload went as expected.  The best way to check for upload errors is wtih the *listBatches* query.  Since this returns all of the batches in a submission, you'll have to do a little parsing to see if there are any issues with the batch you just sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13365683-4395-427b-a341-6d24b1aa7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_batches_query = \"\"\"\n",
    "query ListBatches($submissionID: ID!) {\n",
    "  listBatches(submissionID: $submissionID) {\n",
    "    batches {\n",
    "      _id\n",
    "      submissionID\n",
    "      displayID\n",
    "      type\n",
    "      fileCount\n",
    "      files {\n",
    "        fileName\n",
    "      }\n",
    "      status\n",
    "      errors\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3db57f7e-5e0a-4d77-848e-ec867303541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_variables = {'submissionID':submissionid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0891979-ebf6-40ae-882d-3adf2a9c753a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'listBatches': {'batches': [{'_id': 'e391e412-e4ad-4a91-ba5e-fc24cd106652', 'submissionID': 'f41aea9c-bb76-4b48-8b53-27028317b434', 'displayID': 8, 'type': 'metadata', 'fileCount': 9, 'files': [{'fileName': 'PDXNet_participant.tsv'}, {'fileName': 'PDXNet_sample.tsv'}, {'fileName': 'PDXNet_diagnosis.tsv'}, {'fileName': 'PDXNet_file.tsv'}, {'fileName': 'PDXNet_genomic_info.tsv'}, {'fileName': 'PDXNet_image.tsv'}, {'fileName': 'PDXNet_program.tsv'}, {'fileName': 'PDXNet_study.tsv'}, {'fileName': 'PDXNet_treatment.tsv'}], 'status': 'Failed', 'errors': ['“PDXNet_sample.tsv: 74”: conflict data detected: “sample_type”: \"DNA\".', '“PDXNet_sample.tsv: 38”: conflict data detected: “sample_type”: \"RNA\".', '“PDXNet_image.tsv:2”:  Key property “study_link_id” value is required.', '“PDXNet_treatment.tsv:2”:  Key property “treatment_id” value is required.']}, {'_id': 'ac699a96-08e1-486a-9280-7912d08d64d7', 'submissionID': 'f41aea9c-bb76-4b48-8b53-27028317b434', 'displayID': 7, 'type': 'metadata', 'fileCount': 1, 'files': [{'fileName': 'PDXNet_sample.tsv'}], 'status': 'Failed', 'errors': ['“PDXNet_sample.tsv: 74”: conflict data detected: “sample_type”: \"DNA\".', '“PDXNet_sample.tsv: 38”: conflict data detected: “sample_type”: \"RNA\".']}, {'_id': '5cb96a32-f015-470f-bfdd-c7d3f28e1ce2', 'submissionID': 'f41aea9c-bb76-4b48-8b53-27028317b434', 'displayID': 6, 'type': 'metadata', 'fileCount': 2, 'files': [{'fileName': '/home/pihl/testdata/PDXNet_participant.tsv'}, {'fileName': '/home/pihl/testdata/PDXNet_sample.tsv'}], 'status': 'Uploading', 'errors': None}, {'_id': 'da8bfe78-b227-42e9-9291-8934391151e2', 'submissionID': 'f41aea9c-bb76-4b48-8b53-27028317b434', 'displayID': 5, 'type': 'metadata', 'fileCount': 2, 'files': [{'fileName': '/home/pihl/testdata/PDXNet_participant.tsv'}, {'fileName': '/home/pihl/testdata/PDXNet_sample.tsv'}], 'status': 'Uploading', 'errors': None}, {'_id': 'e1937bd6-f659-4275-a5b7-9ac387f4fde8', 'submissionID': 'f41aea9c-bb76-4b48-8b53-27028317b434', 'displayID': 4, 'type': 'metadata', 'fileCount': 2, 'files': [{'fileName': '/media/vmshare/PDXNet_participant.tsv'}, {'fileName': '/media/vmshare/PDXNet_sample.tsv'}], 'status': 'Uploading', 'errors': None}, {'_id': '6fbf7ba1-27c2-4040-86c9-1858e15eb4be', 'submissionID': 'f41aea9c-bb76-4b48-8b53-27028317b434', 'displayID': 3, 'type': 'metadata', 'fileCount': 2, 'files': [{'fileName': '/media/vmshare/PDXNet_participant.tsv'}, {'fileName': '/media/vmshare/PDXNet_sample.tsv'}], 'status': 'Uploading', 'errors': None}, {'_id': '3b08b7a7-a746-4724-b7da-99fb5e889f4c', 'submissionID': 'f41aea9c-bb76-4b48-8b53-27028317b434', 'displayID': 2, 'type': 'metadata', 'fileCount': 2, 'files': [{'fileName': '/media/vmshare/PDXNet_participant.tsv'}, {'fileName': '/media/vnshare/PDXNet_sample.tsv'}], 'status': 'Uploading', 'errors': None}, {'_id': 'b3fa1b09-42d5-40ee-8dc2-88e8a2b4156f', 'submissionID': 'f41aea9c-bb76-4b48-8b53-27028317b434', 'displayID': 1, 'type': 'metadata', 'fileCount': 2, 'files': [{'fileName': '/media/vmshare/PDXNet_participant.tsv'}, {'fileName': '/media/vnshare/PDXNet_sample.tsv'}], 'status': 'Uploading', 'errors': None}]}}}\n"
     ]
    }
   ],
   "source": [
    "batch_error_res = apiQuery(dev2, list_batches_query, batches_variables, None)\n",
    "print(batch_error_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d3bb947-0f47-40ba-b5b3-d3f3528f0a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|    | _id                                  | submissionID                         |   displayID | type     |   fileCount | files                                                                                                                                                                                                                                                                                                                                     | status    | errors                                                                                                                                                                                                                                                                                                      |\n",
       "|---:|:-------------------------------------|:-------------------------------------|------------:|:---------|------------:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
       "|  0 | e391e412-e4ad-4a91-ba5e-fc24cd106652 | f41aea9c-bb76-4b48-8b53-27028317b434 |           8 | metadata |           9 | [{'fileName': 'PDXNet_participant.tsv'}, {'fileName': 'PDXNet_sample.tsv'}, {'fileName': 'PDXNet_diagnosis.tsv'}, {'fileName': 'PDXNet_file.tsv'}, {'fileName': 'PDXNet_genomic_info.tsv'}, {'fileName': 'PDXNet_image.tsv'}, {'fileName': 'PDXNet_program.tsv'}, {'fileName': 'PDXNet_study.tsv'}, {'fileName': 'PDXNet_treatment.tsv'}] | Failed    | ['“PDXNet_sample.tsv: 74”: conflict data detected: “sample_type”: \"DNA\".', '“PDXNet_sample.tsv: 38”: conflict data detected: “sample_type”: \"RNA\".', '“PDXNet_image.tsv:2”:  Key property “study_link_id” value is required.', '“PDXNet_treatment.tsv:2”:  Key property “treatment_id” value is required.'] |\n",
       "|  1 | ac699a96-08e1-486a-9280-7912d08d64d7 | f41aea9c-bb76-4b48-8b53-27028317b434 |           7 | metadata |           1 | [{'fileName': 'PDXNet_sample.tsv'}]                                                                                                                                                                                                                                                                                                       | Failed    | ['“PDXNet_sample.tsv: 74”: conflict data detected: “sample_type”: \"DNA\".', '“PDXNet_sample.tsv: 38”: conflict data detected: “sample_type”: \"RNA\".']                                                                                                                                                        |\n",
       "|  2 | 5cb96a32-f015-470f-bfdd-c7d3f28e1ce2 | f41aea9c-bb76-4b48-8b53-27028317b434 |           6 | metadata |           2 | [{'fileName': '/home/pihl/testdata/PDXNet_participant.tsv'}, {'fileName': '/home/pihl/testdata/PDXNet_sample.tsv'}]                                                                                                                                                                                                                       | Uploading |                                                                                                                                                                                                                                                                                                             |\n",
       "|  3 | da8bfe78-b227-42e9-9291-8934391151e2 | f41aea9c-bb76-4b48-8b53-27028317b434 |           5 | metadata |           2 | [{'fileName': '/home/pihl/testdata/PDXNet_participant.tsv'}, {'fileName': '/home/pihl/testdata/PDXNet_sample.tsv'}]                                                                                                                                                                                                                       | Uploading |                                                                                                                                                                                                                                                                                                             |\n",
       "|  4 | e1937bd6-f659-4275-a5b7-9ac387f4fde8 | f41aea9c-bb76-4b48-8b53-27028317b434 |           4 | metadata |           2 | [{'fileName': '/media/vmshare/PDXNet_participant.tsv'}, {'fileName': '/media/vmshare/PDXNet_sample.tsv'}]                                                                                                                                                                                                                                 | Uploading |                                                                                                                                                                                                                                                                                                             |\n",
       "|  5 | 6fbf7ba1-27c2-4040-86c9-1858e15eb4be | f41aea9c-bb76-4b48-8b53-27028317b434 |           3 | metadata |           2 | [{'fileName': '/media/vmshare/PDXNet_participant.tsv'}, {'fileName': '/media/vmshare/PDXNet_sample.tsv'}]                                                                                                                                                                                                                                 | Uploading |                                                                                                                                                                                                                                                                                                             |\n",
       "|  6 | 3b08b7a7-a746-4724-b7da-99fb5e889f4c | f41aea9c-bb76-4b48-8b53-27028317b434 |           2 | metadata |           2 | [{'fileName': '/media/vmshare/PDXNet_participant.tsv'}, {'fileName': '/media/vnshare/PDXNet_sample.tsv'}]                                                                                                                                                                                                                                 | Uploading |                                                                                                                                                                                                                                                                                                             |\n",
       "|  7 | b3fa1b09-42d5-40ee-8dc2-88e8a2b4156f | f41aea9c-bb76-4b48-8b53-27028317b434 |           1 | metadata |           2 | [{'fileName': '/media/vmshare/PDXNet_participant.tsv'}, {'fileName': '/media/vnshare/PDXNet_sample.tsv'}]                                                                                                                                                                                                                                 | Uploading |                                                                                                                                                                                                                                                                                                             |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_df = pd.DataFrame(batch_error_res['data']['listBatches']['batches'])\n",
    "display(Markdown(batch_df.to_markdown()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880d32d2-1e45-4403-bd55-942fe7a51225",
   "metadata": {},
   "source": [
    "Clearly there were some issues associated with the sample file that have to be corrected.  From the error message, it looks like there is a conflict in that the same sample has different sample_types.  While this almost certainly reflects a "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
